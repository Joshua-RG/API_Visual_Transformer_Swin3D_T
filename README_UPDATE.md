# Actualizaci贸n del Backend: Integraci贸n de Filtro de Personas (YOLOv8n)

Hola,

He implementado el pre-filtro de conteo de personas en el *pipeline* del backend.

El **objetivo** es optimizar el `inference_service` (el proceso de la GPU) para que nuestro modelo principal (Swin3D-T) solo analice clips cuando haya **2 o m谩s personas** en la escena. Esto evita que la GPU procese clips de escenas vac铆as o con una sola persona, reduciendo dr谩sticamente la carga de trabajo y los falsos positivos.

Para implementar esto, tuve que crear 2 archivos nuevos y modificar 2 existentes. Aqu铆 est谩 el detalle completo para que puedas actualizar la versi贸n del backend:

---

## 1.  Nuevos Archivos A帽adidos

### 1.1. Nuevo Modelo de Detecci贸n (YOLO)

* **Archivo:** `model_api/onnx_model/person_detector/yolov8n.onnx`
* **Descripci贸n:** Es el modelo **YOLOv8n (nano)** pre-entrenado, exportado a formato ONNX (opset 12). Este es el modelo ligero que usaremos para el conteo r谩pido de personas.

### 1.2. Nuevo "Wrapper" del Detector de Personas

* **Archivo:** `model_api/onnx_model/onnx_person_detector.py`
* **Descripci贸n:** Cre茅 esta nueva clase `PersonDetector` (siguiendo el mismo estilo de nuestro `onnx_detector.py`) que encapsula toda la l贸gica de YOLO:
    * **Carga (Lazy Loading):** Carga el modelo `yolov8n.onnx`.
    * **Proveedor Forzado:** Est谩 configurada para usar **`'CPUExecutionProvider'`**. Esto es crucial para que el filtro corra en la CPU del *worker* y no compita con el `inference_service` de la GPU.
    * **Funciones:** Contiene `_preprocess()` (para redimensionar el frame a 320x320), `_postprocess()` (para contar las detecciones de la clase 0 - "persona"), y la funci贸n principal `count_persons(frame)`.

---

## 2.  Archivos Modificados

### 2.1. `run_app.py` (El Orquestador)

* **Objetivo del Cambio:** Darle al `camera_worker` acceso (permiso) al `results_queue`.
* **Funci贸n Modificada:** `main()`.
* **Detalle del Cambio:**
    * Dentro del bucle `for cam in cameras_to_run:`, modifiqu茅 los `args` (argumentos) que se pasan al proceso `run_camera_worker`.
    * **Par谩metro A帽adido:** Ahora le pasamos la `results_queue` al final de la tupla de `args`, despu茅s del `control_queues[cam["id"]]`.
* **Por qu茅:** El `camera_worker` ahora necesita "saltarse" la GPU y enviar predicciones `[0.0, 0.0, 0.0]` directamente al `event_manager`. Como el `event_manager` ya escucha el `results_queue`, el *worker* necesitaba acceso a esa cola para implementar el *bypass*.

### 2.2. `model_api/services/camera_worker.py` (El Worker de CPU)

Este es el cambio m谩s importante. Aqu铆 es donde se implementa toda la nueva l贸gica de filtrado.

* **Objetivo del Cambio:** Integrar el `PersonDetector` para filtrar los clips antes de enviarlos a la GPU.
* **Nuevos Imports:**
    * `from onnx_model.onnx_person_detector import PersonDetector`.
* **Funci贸n Modificada:** `run_camera_worker(...)`.
* **Nuevos Par谩metros de Funci贸n:**
    * La firma de la funci贸n ahora acepta `results_queue: Queue` al final. (Esto coincide con el cambio en `run_app.py`).
* **Variables Nuevas (dentro de la funci贸n):**
    * `person_detector: Union[PersonDetector, None] = None`.
    * Al inicio de la funci贸n (Secci贸n `1. Inicializaci贸n`), ahora instanciamos `person_detector = PersonDetector()`. Esto carga el modelo YOLO en la memoria de la CPU **una sola vez** por *worker*, lo cual es muy eficiente.
* **L贸gica Modificada (La parte m谩s importante):**
    * La l贸gica de inferencia en la **Secci贸n `2d. L贸gica de Inferencia`**, que comenzaba con `if (len(inference_buffer) == INFERENCE_BUFFER_SIZE and ...)`, fue **completamente reescrita**.
    * **Paso 1 (Filtro):** Ahora, lo primero que hacemos dentro de ese `if` es llamar a `person_count = person_detector.count_persons(frame)`. Usamos el `frame` m谩s reciente para la detecci贸n.
    * **Paso 2 (Decisi贸n):** Se implement贸 una nueva l贸gica `if/elif/else`:
        * **`if person_count >= 2:` (Camino Caro):**
            * Si hay 2 o m谩s personas, se ejecuta la l贸gica *anterior*.
            * Llama a `preprocess_clip(list(inference_buffer))`.
            * Pone el *tensor* de video resultante en la `inference_queue` (para la GPU).
        * **`elif person_count < 0:` (Manejo de Errores):**
            * Si YOLO falla (devuelve -1), solo se loguea el error y se omite el ciclo.
        * **`else: (person_count < 2)` (Camino Barato / Bypass):**
            * Si hay 0 o 1 persona, **NO** se llama a `preprocess_clip()` (隆Ahorro de CPU!).
            * **NO** se pone nada en la `inference_queue` (隆Ahorro de GPU!).
            * Se crea `neutral_probs = np.array([0.0] * len(config.CLASSES))`.
            * Se pone `neutral_probs` **directamente en la `results_queue`**. Esto es para que el `event_manager` reciba un `[0,0,0]` y el *frontend* sepa que la c谩mara sigue viva.
            * Se actualiza `last_known_probs = neutral_probs` para que el `EventRecorder` guarde los datos correctos si justo estaba grabando.

---

## 3.  Resumen de Tareas para Actualizar

Para actualizar el backend, necesitas hacer lo siguiente:

1.  **A帽adir Nuevos Archivos:**
    * Aseg煤rate de tener el modelo en: `model_api/onnx_model/person_detector/yolov8n.onnx`.
    * A帽ade el nuevo archivo: `model_api/onnx_model/onnx_person_detector.py`.
2.  **Actualizar Archivos:**
    * Reemplaza el contenido de `run_app.py` con la nueva versi贸n.
    * Reemplaza el contenido de `model_api/services/camera_worker.py` con la nueva versi贸n.
3.  **Verificar Dependencias:**
    * El `PersonDetector` necesita `onnxruntime` (la versi贸n de CPU, 隆no `onnxruntime-gpu`!). El script de exportaci贸n de YOLO (que corr铆 yo) ya deber铆a haberlo instalado en el `venv_api`.